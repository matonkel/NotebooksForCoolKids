{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Overview Data Science\n",
    "\n",
    "__Data Science__ - the basis for emperical research where data is used to inform hypothesis and inform observations\n",
    "\n",
    "Data science is used by buisnesses and/or scientists to inform their understanding of phenomena.\n",
    "\n",
    "__Big Data__ - large data sets\n",
    "\n",
    "__Insight__ - Product of Data Science\n",
    "\n",
    "> _Insights_ need to be well reasoned so that organizations and companies can use them to take action.\n",
    "\n",
    "Data science is not a static process.  Insights need to be added to new data and reanalysed.  The goal is to produce actionable information.\n",
    "\n",
    "### Data Science\n",
    "\n",
    "#### Basic Steps\n",
    "Acquire ---> Prepare ---> Analyze ---> Report ---> Act\n",
    " \n",
    "> Before we can begin to Science the shit out of things, we need a question to answer.\n",
    "\n",
    "To be succesful, we need to ask the right question.  We __Formulate__ that question if we:\n",
    "- Define the problem well.\n",
    "- Assess the situation with respect to:\n",
    "    - Risks\n",
    "    - Benifits\n",
    "    - Cost\n",
    "    - Requirements\n",
    "    - Resources\n",
    "    - Contingencies\n",
    "    - Regulations\n",
    "- Define Goals & Objectives\n",
    "    - Define Success Critera\n",
    "    - Be Clear\n",
    " \n",
    "##### 1. Acquire\n",
    "\n",
    "ID data sets ---> Retrive data ---> Query data\n",
    "\n",
    "> Locate and import raw data sets into you enviroment or analytics platform.  Downloads, API's, and Web Sockets will be instrumental in this.\n",
    "\n",
    "\n",
    "Data comes in forms such as:\n",
    "* __Databases__ - Relational & Non-relational\n",
    "* __Textfiles__ - CSV & textfiles\n",
    "* __Live Feeds__ - Sensors & online Platforms\n",
    "\n",
    "##### 2. Prepare\n",
    "Explore (_Understand -> Prelim-analysis_) ---> Preprocess (_Clean -> Integrate -> Package_)\n",
    "\n",
    "> Goal: Understand your data.\n",
    "\n",
    "###### 2.1 Exploring Data\n",
    "\n",
    "<div class=\"alert alert-danger\"><strong>DO NOT SKIP THIS STEP</strong></div>\n",
    "\n",
    "Look for correlations, trends, and outliers in the data.  Compile some summary statistics.  Mean, median, mode, standard deviation.\n",
    "> This pre analysis can tell you if there are any issues with your data.\n",
    "\n",
    "##### 3. Analyze\n",
    "Analytical Technique Selection ---> Build Model ---> Iterate if needed\n",
    "\n",
    ">\n",
    "\n",
    "##### 4. Report\n",
    "Communicate Results ---> Choose Visual Means of Display ---> Assessment of Results\n",
    "\n",
    ">\n",
    "\n",
    "##### 5. Act\n",
    "Apply Foot to Ass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "### Why Python?\n",
    "__Data Science__ happens at the intersection of Mathmatics, Computer Science, and Business expertise.\n",
    "\n",
    "> _Python_ is easy to read & learn, an open language, with a vibrant community with an evergrowing set of libraries for Data Management, Analytical Processing, & Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=3\n",
    "y=3.0\n",
    "x is y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercise: Create a comprehension function for a dictionary that lists uppercase A-Z as values and their  correponding ASCii values as the key\n",
    "\n",
    "__chr__ method takes a single AscII integer and yeilds it's charcter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{65: 'A',\n",
       " 66: 'B',\n",
       " 67: 'C',\n",
       " 68: 'D',\n",
       " 69: 'E',\n",
       " 70: 'F',\n",
       " 71: 'G',\n",
       " 72: 'H',\n",
       " 73: 'I',\n",
       " 74: 'J',\n",
       " 75: 'K',\n",
       " 76: 'L',\n",
       " 77: 'M',\n",
       " 78: 'N',\n",
       " 79: 'O',\n",
       " 80: 'P',\n",
       " 81: 'Q',\n",
       " 82: 'R',\n",
       " 83: 'S',\n",
       " 84: 'T',\n",
       " 85: 'U',\n",
       " 86: 'V',\n",
       " 87: 'W',\n",
       " 88: 'X',\n",
       " 89: 'Y',\n",
       " 90: 'Z'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {i:chr(i) for i in range(65,91)}\n",
    "dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Sets\n",
    " Useful data structure becasue they support a number of math operations and tehy only allow unique elements\n",
    " \n",
    " __Set__s are:\n",
    "- Unordered\n",
    "- Unique\n",
    "- Support set operations\n",
    "\n",
    "##### Unordered\n",
    "    Makes sets incredibly fast for a number of key operations\n",
    "\n",
    "##### Unique\n",
    "    No duplicates\n",
    "    \n",
    "##### Support set opperations\n",
    "    Such as Union and intersection\n",
    "\n",
    "#### Set Basics\n",
    "##### Create and Add\n",
    ">Create sets by using the keyword **set** , then pass a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue', 'green', 'red'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leos_colors = set(['blue', 'green', 'red'])\n",
    "leos_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Add to a set by calling with the 'add' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue', 'green', 'red', 'yellow'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leos_colors.add('yellow')\n",
    "leos_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Trying to add items already present in a set, will not alter the set since sets are Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue', 'green', 'red', 'yellow'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leos_colors.add('blue')\n",
    "leos_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discard\n",
    ">Remove items by passing the 'discard' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue', 'red', 'yellow'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leos_colors.discard('green')\n",
    "leos_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you use discard on an element that isn't present, it will do nothing\n",
    "\n",
    "If you use remove on an element taht isn't present, it will error out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Operations\n",
    ">Union will provide items from sets included in union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue', 'green', 'red', 'yellow'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leos_colors = set(['blue', 'green', 'red'])\n",
    "kays_colors = set (['blue', 'yellow'])\n",
    "either = kays_colors.union(leos_colors)\n",
    "either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Can be useful if you want to know all the unique items that are in two seperate sets\n",
    ">Sets get used a lot to pull out the unique items across two groups of elements or to find unique items in common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Intersect will find items in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both = kays_colors.intersection(leos_colors)\n",
    "both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union can be done with the `|` operator\n",
    ">set1 | set2\n",
    "\n",
    "Intersection can be done with the `&` operator\n",
    ">set1 & set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exercise\n",
    "### Word Cloud\n",
    "You've likely seen word-clouds before, if not, please check here for examples. In order to create word clouds, the software finds the most frequently occurring words in a text file. Our mini-programming assignment will ask you to do just that. We'll use the text of the famous novel by Charles Dickens, A Tale of Two Cities, in our example, but you can use any text you'd like.\n",
    "\n",
    "### Part 1: Writing and running Python code\n",
    "Make sure you have the environment for the course already setup.  If not, please see the instructions at the end of Week 1\n",
    "Feel free to create a Python program using a text editor (nano) or you can do all the work in Python shell.  Or, if you already have some experience in Jupyter, feel free to do your work there instead. We don't want to be prescriptive here, however you'd like to get started programming is fine. We'll be working in Jupyter from this week on, so this assignment is just to get a little practice in Python programming.\n",
    "### Part 2: Grab source files\n",
    "Download the source files here.\n",
    "Included in the source files are:\n",
    "\n",
    "1. word_cloud.py <-- Starter file if you wish to use it\n",
    "2. 98-0.txt <-- Tale of Two Cities, by Charles Dickens. Credit to Project Gutenberg.\n",
    "3. stopwords <-- common words to exclude. Credit to Andreas Mueller.\n",
    "\n",
    "Note that we could use the nltk stopwords instead of those provided. You should feel free to do so if you wish.\n",
    "\n",
    "### Part 3: Word Count\n",
    "To complete this assignment, you will want to read and clean the input, then count the frequencies of each word. Remember that the data science process involves some pre-processing, then consists of some analysis itself. Optionally, you can also filter out common words (“the”, “this”, “and”, etc.) by excluding words which appear in the stopwords file.\n",
    "\n",
    "Overall, your approach will be:\n",
    "\n",
    "- Create a data structure to store the words and the number of occurrences of the word.\n",
    "- Read in each word from the file, making it lower case and removing punctuation. (Optionally, skip common words).\n",
    "    - For each remaining word, add the word to the data structure or update your count for the word\n",
    "- Extract the top ten most frequently occurring words from your data structure and print them, along with their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the :  8177\n",
      "and :  4984\n",
      "of :  4122\n",
      "to :  3536\n",
      "a :  2976\n",
      "in :  2612\n",
      "his :  1998\n",
      "it :  1879\n",
      "i :  1872\n",
      "that :  1861\n"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('word_cloud/word_cloud/98-0.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "# stopwords = set(line.strip() for line in open('stopwords'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in wordcount:\n",
    "        wordcount[word] = 1\n",
    "    else:\n",
    "        wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
